{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c89ebae",
   "metadata": {},
   "source": [
    "## **Practical Lab 3 - Vanilla CNN and Fine-Tune VGG16 - for Dogs and Cats Classification**\n",
    "\n",
    "**Name:** Mandeep Singh Brar        \n",
    "**Student ID:** 8989367     \n",
    "**Course Name:** Foundations of Machine Learning Frameworks         \n",
    "**Course No:** CSCN8010 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85820352",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "In this lab, I will explore the task of image classification by building a model that can distinguish between images of dogs and cats. \n",
    "\n",
    "To understand the strengths of different modeling approaches, I will implement two models:\n",
    "\n",
    "- A Vanilla CNN built from scratch to grasp the core mechanics of convolutional networks.\n",
    "\n",
    "- A Fine-Tuned VGG16 model that applies transfer learning using pre-trained ImageNet weights.\n",
    "\n",
    "Through this process, I aim to deepen my understanding of deep learning workflows, including data preprocessing, model training, evaluation, and fine-tuning. I will evaluate both models using accuracy, precision, recall, F1-score, and confusion matrix to determine which approach performs best for this binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fba307d",
   "metadata": {},
   "source": [
    "#### **Step 1: Obtain the Dataset (Dogs vs. Cats)**\n",
    "\n",
    "I downloaded the Dogs vs. Cats dataset from Kaggle, available here: https://www.kaggle.com/datasets/biaiscience/dogs-vs-cats\n",
    "\n",
    "The full dataset contains 25,000 images, but for the purpose of this lab—and in line with the provided class notebook—I only need a subset of 5,000 images, equally balanced between dogs and cats for training, validation, and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cdd7ad",
   "metadata": {},
   "source": [
    "#### **Step 2: Extract and Organize the Dataset**        \n",
    "\n",
    "After downloading the train.zip file, I extracted it into a folder of my choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60651a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Creating subset: train (0 to 999)\n",
      "----\n",
      "Copied 1000 images to 'train/cat'\n",
      "Copied 1000 images to 'train/dog'\n",
      "\n",
      " Creating subset: validation (1000 to 1499)\n",
      "----\n",
      "Copied 500 images to 'validation/cat'\n",
      "Copied 500 images to 'validation/dog'\n",
      "\n",
      " Creating subset: test (1500 to 2499)\n",
      "----\n",
      "Copied 1000 images to 'test/cat'\n",
      "Copied 1000 images to 'test/dog'\n",
      "\n",
      "\n",
      " Dataset split completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "# Define paths for the original dataset and the destination for the smaller subset\n",
    "original_dir = pathlib.Path(\"Data/train\")  # Folder containing all 25,000 original images\n",
    "new_base_dir = pathlib.Path(\"Data/cats_vs_dogs\")  # Folder where the smaller, organized dataset will be saved\n",
    "\n",
    "# Function to create subsets (train, validation, test) from the full dataset\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    print(f\"\\n Creating subset: {subset_name} ({start_index} to {end_index - 1})\")\n",
    "    print(\"----\")\n",
    "\n",
    "    # Loop over both categories: cats and dogs\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        # Create the directory for the current subset and category if it doesn’t exist\n",
    "        dir = new_base_dir / subset_name / category\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "        # Generate file names like 'cat.0.jpg', 'dog.1001.jpg', etc.\n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        copied = 0  # Counter to track number of copied files\n",
    "\n",
    "        # Copy each image from the original dataset to the new directory\n",
    "        for fname in fnames:\n",
    "            src = original_dir / fname\n",
    "            dst = dir / fname\n",
    "            if src.exists():\n",
    "                shutil.copyfile(src, dst)\n",
    "                copied += 1\n",
    "            else:\n",
    "                # Warn if a file in the expected range is missing\n",
    "                print(f\"Warning: {fname} not found in {original_dir}\")\n",
    "\n",
    "        print(f\"Copied {copied} images to '{subset_name}/{category}'\")\n",
    "\n",
    "# Run the function for each subset: train (1000 per class), validation (500 per class), test (1000 per class)\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\" Dataset split completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b0104e",
   "metadata": {},
   "source": [
    "### **EDA: Explore the data with relevant graphs, statistics and insights**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "life",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
